{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561f5c0d",
   "metadata": {},
   "source": [
    "# Inference and visualization\n",
    "\n",
    "This notebook shows how to run inference and visualize data. We use the awesome `k3d` package for interactive plots in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import k3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gecco_torch\n",
    "from gecco_torch.diffusion import Diffusion\n",
    "from gecco_torch.structs import Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4ddbd",
   "metadata": {},
   "source": [
    "Load the config file and get the model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e19057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../release-checkpoints/taskonomy/'\n",
    "config = gecco_torch.load_config(f'{root}/config.py')\n",
    "model: Diffusion = config.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e939d",
   "metadata": {},
   "source": [
    "Prepare data. This can be skipped entirely if the model is unconditional and we're only interested in inference (generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c3c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = config.data\n",
    "data.setup() # PyTorch lightning data modules need to be setup before use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = f'{root}/lightning_logs/version_0/checkpoints'\n",
    "checkpoints = os.listdir(checkpoints_path)\n",
    "checkpoint_name = next(c for c in checkpoints if c.endswith('.ckpt'))\n",
    "checkpoint_path = os.path.join(checkpoints_path, checkpoint_name)\n",
    "print(f'Using checkpoint {checkpoint_name}')\n",
    "checkpoint_state_dict = torch.load(checkpoint_path, map_location='cpu')\n",
    "model_state_dict = checkpoint_state_dict['ema_state_dict']\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03036e13",
   "metadata": {},
   "source": [
    "Grab a batch of data to have access to the conditioning images and intrinsics matices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5749c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch: Example = next(iter(data.val_dataloader()))\n",
    "print(batch) # print the batch to see what it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the best backend\n",
    "if torch.cuda.is_available():\n",
    "    map_device = lambda x: x.to(device='cuda')\n",
    "else:\n",
    "    map_device = lambda x: x\n",
    "\n",
    "model: Diffusion = map_device(model).eval()\n",
    "context = batch.ctx.apply_to_tensors(map_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6cbbc6",
   "metadata": {},
   "source": [
    "Sample the examples. Since the batch has 48 items, we will sample 48 point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206833a7-2bb2-4931-a3ec-f0c96777544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast('cuda', dtype=torch.float16):\n",
    "    samples = model.sample_stochastic(\n",
    "        (48, 2048, 3),\n",
    "        context=context,\n",
    "        with_pbar=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03a3a6",
   "metadata": {},
   "source": [
    "Visualize the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id = 5 # index within the batch\n",
    "\n",
    "plt.imshow(batch.ctx.image[example_id].permute(1, 2, 0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf738f51",
   "metadata": {},
   "source": [
    "Visualize the point cloud in 3d. Green - ground truth, red - GECCO sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f57b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "plot += k3d.points(samples[example_id].cpu().numpy().astype('float32'), point_size=0.01, color=0xff0000)\n",
    "plot += k3d.points(batch.data[example_id].cpu().numpy().astype('float32'), point_size=0.01, color=0x00ff00)\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a17e1",
   "metadata": {},
   "source": [
    "## Bonus: upsampling\n",
    "GECCO is trained with a specific number of points in each point cloud and at inference time should be used in a similar regime. There is however a trick which allows sampling mulitple new points conditionally on an already existing point cloud. Repeated multiple times and concatenated, we achieve upsampling by creating multiple new points, independent of each other **conditionally on the input data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e826d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick only the current `example_id` to avoid running out of memory\n",
    "pick_id = lambda t: t[example_id:example_id+1]\n",
    "sample_to_upsample = map_device(pick_id(samples))\n",
    "\n",
    "with torch.autocast('cuda', dtype=torch.float16):\n",
    "    upsampled = model.upsample(\n",
    "        n_new=100_000,\n",
    "        data=sample_to_upsample,\n",
    "        context=context.apply_to_tensors(pick_id),\n",
    "        with_pbar=True,\n",
    "        num_steps=32,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0de85f9",
   "metadata": {},
   "source": [
    "Visualize the upsampled point cloud: green - original, red - upsampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "plot += k3d.points(pick_id(samples).squeeze(0).cpu().numpy(), point_size=0.01, color=0x00ff00)\n",
    "plot += k3d.points(upsampled.squeeze(0).cpu().numpy(), point_size=0.01, color=0xff0000)\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47795c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
